{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify Project Workspace\n",
    "This workspace contains a tiny subset (128MB) of the full dataset available (12GB). Feel free to use this workspace to build your project, or to explore a smaller subset with Spark before deploying your cluster on the cloud. Instructions for setting up your Spark cluster is included in the last lesson of the Extracurricular Spark Course content.\n",
    "\n",
    "You can follow the steps below to guide your data analysis and model building portion of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Creating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import (sum, col, when, lit, round, from_unixtime, split, \n",
    "                                   concat, regexp_replace, percentile,\n",
    "                                   count, countDistinct, max, min, avg, \n",
    "                                   date_format, date_part, date_trunc, to_timestamp\n",
    "                                  )\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the changes to the current session\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/workspace/jdk'\n",
    "os.environ['PATH'] = f\"{os.environ['JAVA_HOME']}/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/16 02:21:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Sparkify Project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pandas_dataframe(df_filtered, number_limit = 5):\n",
    "    df_limited = df_filtered.limit(number_limit)\n",
    "    return df_limited.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "In this workspace, the mini-dataset file is `mini_sparkify_event_data.json`. Load and clean the dataset, checking for invalid or missing data - for example, records without userids or sessionids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##reading json\n",
    "df = spark.read.json(\"mini_sparkify_event_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##displaying a sample of data\n",
    "df.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pltting in a pandas df to a better visualization \n",
    "display_pandas_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe has 18 columns, 12 columns being a string value, and the other 6 columns beign numerical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the schema\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 286,5K lines in the Dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Looking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns\n",
    "list_of_columns = df.columns\n",
    "\n",
    "#creating dict to store null values\n",
    "dict_null_values = {col_name: df.filter(col(f'{col_name}').isNull()).count() for col_name in list_of_columns}\n",
    "print(dict_null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few null values in the dataset, mainly in artist, firstName, lastName, gender, leght, location, registration, song and userAgent column. Let's check some rows containing these null records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df.filter(col('artist').isNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.withColumn('is_none_artist', \n",
    "               when(col('artist').isNull(), lit('Null value'))\n",
    "               .otherwise(lit('Not null value'))\n",
    "              )\n",
    "   .withColumn('is_none_song', \n",
    "               when(col('song').isNull(), lit('Null value'))\n",
    "               .otherwise(lit('Not null value'))\n",
    "              )\n",
    "   .withColumn('is_none_length', \n",
    "               when(col('length').isNull(), lit('Null value'))\n",
    "               .otherwise(lit('Not null value'))\n",
    "              )\n",
    ").groupBy('is_none_artist', 'is_none_song', 'is_none_length').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null values in artist, song and length records seems to be related with events not including an interaction with any music. So, we will fill these null values with this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df\n",
    "      .withColumn('artist', when(col('artist').isNull(), lit('no_music_info')).otherwise(col('artist')))\n",
    "      .withColumn('song', when(col('song').isNull(), lit('no_music_info')).otherwise(col('song')))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df.filter(col('location').isNull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a relation between null values in First Name, Last Name, Location, Gender, registration, userAgent with Logged Out sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.withColumn('is_none_gender', \n",
    "               when(col('gender').isNull(), lit('Null value'))\n",
    "               .otherwise(lit('Not null value'))\n",
    "              )\n",
    "   .withColumn('is_none_location', \n",
    "               when(col('location').isNull(), lit('Null value'))\n",
    "               .otherwise(lit('Not null value'))\n",
    "              )\n",
    "   .withColumn('is_none_registration', \n",
    "               when(col('location').isNull(), lit('Null value'))\n",
    "               .otherwise(lit('Not null value'))\n",
    "              )\n",
    "   .withColumn('is_none_userAgent', \n",
    "               when(col('userAgent').isNull(), lit('Null value'))\n",
    "               .otherwise(lit('Not null value'))\n",
    "              )\n",
    ").groupBy('auth',\n",
    "          'is_none_gender', 'is_none_location', \n",
    "          'is_none_registration', 'is_none_userAgent').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we can not know of kow is the user acessing the app in Logged Out Sessions, or Guest Sessions, information about these types of interactions can not be helpful to the Churn Analysis. Also, the represent a small portion of dataset. Due to this, there records will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(col('auth').isin(['Logged In', 'Cancelled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns\n",
    "list_of_columns = df.columns\n",
    "\n",
    "#creating dict to store null values\n",
    "dict_null_values = {col_name: df.filter(col(f'{col_name}').isNull()).count() for col_name in list_of_columns}\n",
    "print(dict_null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, there is no  null value in te dataset, besides the length column, that has null values in cases of song/artist with no music information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Checking Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only one problem with dtypes: datetime information should be in datetime format. This must be true even in registration columns, as in ts column. Let's do this convertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.withColumn('registration_datetime', \n",
    "                    from_unixtime(col('registration')/1000, \n",
    "                                  \"yyyy-MM-dd HH:mm:ss\")\n",
    "                   )\n",
    "         .withColumn('ts_datetime', \n",
    "                    from_unixtime(col('ts')/1000, \n",
    "                                  \"yyyy-MM-dd HH:mm:ss\")\n",
    "                   )\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn('registration_datetime', from_unixtime(col('registration')/1000, \"yyyy-MM-dd HH:mm:ss\")).select('registration_datetime', 'registration', 'ts', 'ts_datetime').limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df\n",
    "      .withColumn('ts', col('ts_datetime'))\n",
    "      .withColumn('registration', col('registration_datetime'))\n",
    "      .drop('registration_datetime', 'ts_datetime')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df.groupBy('userAgent').count().orderBy(col('count').desc()), \n",
    "                         number_limit = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Changing specific columns not so useful: first_name and last_name, location, userAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.withColumn('city', split(col('location'), \",\").getItem(0))\n",
    "        .withColumn('state', split(col('location'), \",\").getItem(1))\n",
    "      .drop('location')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df.groupBy('city').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.withColumn('fullName', concat(concat(col('firstName'), lit(\" \")), col('lastName')))\n",
    "      .drop('firstName', 'lastName')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.withColumn('new_userAgent', regexp_replace(col('userAgent'),\"\\\"|\\'\", \"\"))\n",
    "        .withColumn('new_userAgent', regexp_replace(col('new_userAgent'),\"Mozilla/5.0\", \"\"))\n",
    "        .withColumn('operacional_system', when(col('new_userAgent').like('%Windows%'), lit('Windows'))\n",
    "                                         .when(col('new_userAgent').like('%Ubuntu%'), lit('Ubuntu/Linux'))\n",
    "                                         .when(col('new_userAgent').like('%Linux%'), lit('Ubuntu/Linux'))\n",
    "                                         .when(col('new_userAgent').like('%Mobi%'), lit('Mobi'))\n",
    "                                         .when(col('new_userAgent').like('%Mac%'), lit('Mac'))\n",
    "                   )\n",
    "         .withColumn('userAgent', col('operacional_system'))\n",
    "         .drop('new_userAgent', 'operacional_system')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "When you're working with the full dataset, perform EDA by loading a small subset of the data and doing basic manipulations within Spark. In this workspace, you are already provided a small subset of data you can explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics of numerical values. \n",
    "#Columns as registration and ts will not be included because, \n",
    "#besides the fact that they are numerical, the meaning of these columns is a datetime.\n",
    "df.select('itemInSession', 'length', 'sessionId', 'status').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are sessions in the dataset from just one interaction in the dataset to sessions with a thousand of interactions.\n",
    "\n",
    "The length of song has a mean of 249 s, and the derivation is high, with a stddev of 100. Also, there are a few musics with less than 1 second, which must indicate a bug or wrong field.A lenght of 1321 seems to not be real too. \n",
    "\n",
    "The sessions are from 1 to 2474, and, as expected, the status value has the major records with 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we found a lot of max and mins stranges at item length, let's see the distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.select('length').toPandas().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('length').select(round(percentile(col('length'), 1), 2).alias('max'),\n",
    "                          round(percentile(col('length'), 0.999), 2).alias('p_99.9'),\n",
    "                          round(percentile(col('length'), 0.99), 2).alias('_p99'),\n",
    "                          round(percentile(col('length'), 0.95), 2).alias('_p95'),\n",
    "                          round(percentile(col('length'), 0.90), 2).alias('_p90'),\n",
    "                          round(percentile(col('length'), 0.50), 2).alias('_p50')\n",
    "                          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the existence of outliers is clear, based on this right-skewed long-tail distribution. Also, the distributions indicate that the percentile 99 had a length of 591, far away from the max 3024 observed in max. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.filter(col('artist')!='no_music_info')\n",
    "   .groupBy('artist')\n",
    "   .count()\n",
    "   .orderBy(col('count').desc())\n",
    "   .withColumn('total', sum(col('count')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('percent', round(col('count')/col('total'), 4))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no an artist or song that has a higher percent of interactions in the app. However, there is a few artists that has a bbigger interactions than all the others. The top 2 are: Kings Of Leon, Coldplay, with more than 1,5% of songs played togheter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy('gender')\n",
    "   .count()\n",
    "   .orderBy(col('count').desc())\n",
    "   .withColumn('total', sum(col('count')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('percent', round(col('count')/col('total'), 4))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The public between Females and Males in weel distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy('level')\n",
    "   .agg(count(col('userId')).alias('count'),\n",
    "        countDistinct(col('userId')).alias('users')\n",
    "       )\n",
    "   .orderBy(col('count').desc())\n",
    "   .withColumn('total', sum(col('count')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('total_users', sum(col('users')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('percent', round(col('count')/col('total'), 4))\n",
    "   .withColumn('percent_users', round(col('users')/col('total_users'), 4))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus than 75% of interactions are made on paid accounts. However, this doens't means that we has more paid accounts in the app, they are just the public with more interactions.\n",
    "More the 54% of users, actually, are in free accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_fd = (df.groupBy('page', 'level').count().orderBy((col('count').desc())).toPandas())\n",
    "sns.barplot(data=pandas_fd, x='count', y='page', hue='level', palette = 'pastel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paid and Free accounts in general has similar interactions, but with a lower frequency in free acounts. Also, there  are a few pages that are more comom percentually in free accounts, for example, Roll Advert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy('city', 'state')\n",
    "   .count()\n",
    "   .orderBy(col('count').desc())\n",
    "   .withColumn('total', sum(col('count')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('percent', round(col('count')/col('total'), 4))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy('userAgent')\n",
    "   .count()\n",
    "   .orderBy(col('count').desc())\n",
    "   .withColumn('total', sum(col('count')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('percent', round(col('count')/col('total'), 4))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plus than 10% of the interactions are in LA, and more than a half of interactions are in Windows systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Churn\n",
    "\n",
    "Once you've done some preliminary analysis, create a column `Churn` to use as the label for your model. I suggest using the `Cancellation Confirmation` events to define your churn, which happen for both paid and free users. As a bonus task, you can also look into the `Downgrade` events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy('auth')\n",
    "   .count()\n",
    "   .orderBy(col('count').desc())\n",
    "   .withColumn('total', sum(col('count')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('percent', round(col('count')/col('total'), 4))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 52 records with the flag Cancelled in auth information. Let's take a look in pages info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupBy('page', 'auth')\n",
    "   .count()\n",
    "   .orderBy(col('count').desc())\n",
    "   .withColumn('total', sum(col('count')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('percent', round(col('count')/col('total'), 4))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.filter(col('page')=='Cancellation Confirmation')\n",
    "   .groupBy('level', 'auth')\n",
    "   .count()\n",
    "   .orderBy(col('count').desc())\n",
    "   .withColumn('total', sum(col('count')).over(Window.partitionBy(lit(1))))\n",
    "   .withColumn('percent', round(col('count')/col('total'), 4))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the auth Cancelled records are registered in the same page equal to Cancellation Confirmed. It seems to be a reliable information of Cancelled account. \n",
    "Let's create the churn column. We will create a column 'is_churn_event' and a 'is_churn user'. The first one will just give the info of churn in a event level, while the second one will give information in a user level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = (df.withColumn('is_churn_event', \n",
    "                          when(col('page')=='Cancellation Confirmation', lit(1))\n",
    "                          .otherwise(lit(0))\n",
    "             )\n",
    "              .withColumn('is_user_churn', \n",
    "                          max(col('is_churn_event')\n",
    "                             ).over(Window.partitionBy(col('userId')))\n",
    "             )\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe((df_churn.filter(col('is_churn_event')==1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df_churn.filter(col('sessionId')==174).filter(col('userId')==125), number_limit=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look in Downgrade Event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.filter(col('page').isin('Downgrade'))\n",
    "         .groupBy('is_user_churn', 'is_churn_event', 'page')\n",
    "         .agg(countDistinct(col('userId')).alias('users'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.groupBy('is_user_churn')\n",
    "         .agg(countDistinct(col('userId')).alias('users'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides every user, the tax churn rate is 23%. Between users that visited the Downgrade page, the rate is 35%. Let's create a column to indicates the downgrade too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = (df_churn.withColumn('is_downgrade_event', \n",
    "                          when(col('page')=='Downgrade', lit(1))\n",
    "                          .otherwise(lit(0))\n",
    "             )\n",
    "              .withColumn('times_user_downgrade', \n",
    "                          sum(col('is_downgrade_event')\n",
    "                             ).over(Window.partitionBy(col('userId')))\n",
    "             )\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(df_churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, a user just downgrade their plan if he had once a paid plan. Let's create a column to indicate if the user had onde the paid account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = (df_churn.withColumn('had_paid_account', \n",
    "                          when(col('level')=='paid', lit(1))\n",
    "                          .otherwise(lit(0))\n",
    "             )\n",
    "              .withColumn('had_paid_account', \n",
    "                          max(col('had_paid_account')\n",
    "                             ).over(Window.partitionBy(col('userId')))\n",
    "             )\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.groupBy('is_user_churn', 'had_paid_account')\n",
    "         .agg(avg(col('times_user_downgrade')).alias('downgrades_average'),\n",
    "              countDistinct(col('userId')).alias('users'),\n",
    "              countDistinct(when(col('times_user_downgrade')>0, col('userId'))).alias('users_w_downgrades')\n",
    "            )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results above, the downgrades indicates a propensity to cancellate the account. However, there are a lot of customers that downgraded their plans (119 of 129) that do not churn the app. So, to churn rule, we will ust use the Cancellation Information, even that the downgrade column is created and can be use in the further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data\n",
    "Once you've defined churn, perform some exploratory data analysis to observe the behavior for users who stayed vs users who churned. You can start by exploring aggregates on these two groups of users, observing how much of a specific action they experienced per a certain time unit or number of songs played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.groupBy('is_user_churn')\n",
    "         .agg(round(sum(col('length')), 0).alias('time_listen'),\n",
    "              countDistinct(col('userId')).alias('users'),\n",
    "              round((sum(col('length'))/countDistinct(col('userId'))), 0).alias('avg_time_listen'),\n",
    "             )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.groupBy('is_user_churn')\n",
    "         .agg(count(col('song')).alias('play_times'),\n",
    "              countDistinct(col('song')).alias('distinct_songs'),\n",
    "              round(count(col('song'))/countDistinct(col('userId')), 0).alias('avg_time_listen'),\n",
    "              round(countDistinct(col('song'))/countDistinct(col('userId')), 0).alias('avg_distinct_songs'),\n",
    "              round(countDistinct(col('artist'))/countDistinct(col('userId')), 0).alias('avg_distinct_artist'),\n",
    "             )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, users who churned has a lower average time listening songs. Besides the time listening, the number of songs played are lower too. In terms of distinct songs, actually the users who churn has a higher average of distinct songs played, indicating that they used te app to know musics, but heir freuency by song is not big as the users who not churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.groupBy('is_user_churn', 'userId')\n",
    "         .agg(countDistinct(col('page')).alias('pages_interaction'))\n",
    "         .groupBy('is_user_churn')\n",
    "         .agg(avg(col('pages_interaction')))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.filter(col('page')!='NextSong')\n",
    "         .groupBy('is_user_churn', 'userId', 'page')\n",
    "         .agg(count(col('page')).alias('pages_interaction'))\n",
    "         .groupBy('is_user_churn', 'page')\n",
    "         .agg(sum(col('pages_interaction')).alias('pages_interaction'))\n",
    "         .withColumn('total_interactions', \n",
    "                     sum(col('pages_interaction')).over(Window.partitionBy(col('is_user_churn')))\n",
    "                    )\n",
    "         .withColumn('percent', col('pages_interaction')/col('total_interactions'))\n",
    "         .groupBy('page')\n",
    "         .agg(round(sum(when(col('is_user_churn')==1, col('percent')))*100, 2).alias('churn_user_percent'),\n",
    "              round(sum(when(col('is_user_churn')==0, col('percent')))*100, 2).alias('not_churn_user_percent')\n",
    "             )\n",
    "         .orderBy(col('churn_user_percent').desc())\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on table above, it seems that both users has similars interactions between pages, excepting the page Roll Advert and Thumbs Down, that seems to be more frequent to churn users. On the other hand, users hnow not churn, has more interactions, in share, with Thumbs Up and sharing with Friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.groupBy('is_user_churn', 'userId')\n",
    "         .agg(countDistinct(date_format(col('ts'), 'yyyy-MM-dd')).alias('days_interacting'))\n",
    "         .groupBy('is_user_churn')\n",
    "         .agg(avg(col('days_interacting')))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.groupBy('is_user_churn', 'userId')\n",
    "         .agg(countDistinct(date_part(lit('WEEK'), col('ts'))).alias('days_interacting'))\n",
    "         .groupBy('is_user_churn')\n",
    "         .agg(avg(col('days_interacting')))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of days and week interacting besides who not churn is higher than user who churn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.groupBy('is_user_churn', 'gender')\n",
    "         .agg(countDistinct(col('userId')).alias('users'))\n",
    "         .withColumn('user_per_gender', sum(col('users')).over(Window.partitionBy(col('gender'))))\n",
    "         .withColumn('percent', col('users')/col('user_per_gender'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to not have a relation between churn and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_churn.withColumn('month_cohort', date_trunc('month', col('registration')))\n",
    " .groupBy('month_cohort')\n",
    " .agg((countDistinct(when(col('is_user_churn')==1, col('userId')))/countDistinct(col('userId'))).alias('churn_rate'),\n",
    "      countDistinct(col('userId')).alias('users')\n",
    "     )\n",
    " .orderBy(col('month_cohort'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with some months the churn rate being high, this is more related with the fact that the numer of users is small, than related to the fact that the churn is really bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Once you've familiarized yourself with the data, build out the features you find promising to train your model on. To work with the full dataset, you can follow the following steps.\n",
    "- Write a script to extract the necessary features from the smaller subset of data\n",
    "- Ensure that your script is scalable, using the best practices discussed in Lesson 3\n",
    "- Try your script on the full data set, debugging your script if necessary\n",
    "\n",
    "If you are working in the classroom workspace, you can just extract features based on the small subset of data contained here. Be sure to transfer over this work to the larger dataset when you work on your Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##firstly let's remove the cancellation record\n",
    "df_churn = df_churn.filter(col('is_churn_event')!=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_info(df, expression, col_names):\n",
    "    agregacoes = []\n",
    "    for col_name in col_names:\n",
    "    # adding expressions\n",
    "        agregacoes.append(expression(col(col_name)).alias(f\"{expression.__name__}_{col_name}\"))\n",
    "\n",
    "    # Realiza o agrupamento e aplica as agregações\n",
    "    df_agg = df.groupBy('userId').agg(*agregacoes)\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Song/Artist Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = (df_churn.withColumn('date_event', date_format(col('ts'), 'yyyy-MM-dd'))\n",
    "                    .withColumn('hour_event', date_part(lit('M'), col('ts')))\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_song_events = (df_churn.filter(col('song')!='no_music_info'))\n",
    "no_song_events = (df_churn.filter(col('song')=='no_music_info'))\n",
    "\n",
    "unique_song_artist = get_user_info(only_song_events, countDistinct, ['artist', 'song'])\n",
    "song = get_user_info(only_song_events, count, ['song'])\n",
    "no_song = get_user_info(no_song_events, count, ['song']).withColumnRenamed('count_song', 'no_song_events')\n",
    "unique_song_length = get_user_info(only_song_events, sum, ['length'])\n",
    "days_listining = get_user_info(only_song_events, countDistinct, ['date_event', 'hour_event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##agregating all songs info:\n",
    "song_features_agg = (unique_song_artist\n",
    "                     .join(song, on =['userId'], how = 'full')\n",
    "                     .join(no_song, on =['userId'], how = 'full')\n",
    "                     .join(unique_song_length, on =['userId'], how = 'full')\n",
    "                     .join(days_listining, on =['userId'], how = 'full')\n",
    "                     .withColumn('songs_per_day', col('count_song')/col('countDistinct_date_event'))\n",
    "                     .withColumn('songs_per_hour', col('count_song')/col('countDistinct_hour_event'))\n",
    "                     .withColumn('length_per_day', col('sum_length')/col('countDistinct_date_event'))\n",
    "                     .withColumn('minutes_per_day', col('countDistinct_hour_event')/col('countDistinct_date_event'))\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(song_features_agg, number_limit = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Interaction in App Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions_info = (df.groupBy('userId', 'sessionId')\n",
    "                      .agg(min(col('ts')).alias('start_date_session'),\n",
    "                           max(col('ts')).alias('end_date_sessions')\n",
    "                          )\n",
    "                      .withColumn('start_date_session', to_timestamp(col('start_date_session')))\n",
    "                      .withColumn('end_date_sessions', to_timestamp(col('end_date_sessions')))\n",
    "                      .withColumn('session_duration', \n",
    "                                  col('end_date_sessions')-col('start_date_session'))\n",
    "                    .withColumn(\"session_duration_minutes\",\n",
    "                                (col(\"end_date_sessions\").cast(\"long\") - col(\"start_date_session\").cast(\"long\")) / 60\n",
    "                                )\n",
    "                   )\n",
    "\n",
    "df_user_interation_info = (df.groupBy('userId')\n",
    "                      .agg(min(col('ts')).alias('start_date'),\n",
    "                           max(col('ts')).alias('end_date')\n",
    "                          )\n",
    "                      .withColumn('start_date', to_timestamp(col('start_date')))\n",
    "                      .withColumn('end_date', to_timestamp(col('end_date')))\n",
    "                    .withColumn(\"days_between_sessions\",\n",
    "                                (col(\"end_date\").cast(\"long\") - col(\"start_date\").cast(\"long\")) / (60*60*24)\n",
    "                                )\n",
    "                      .drop('start_date', 'end_date')\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sessions = get_user_info(df_churn, countDistinct, ['sessionId'])\n",
    "unique_logs = get_user_info(df_churn, count, ['userId'])\n",
    "sessions_duration = get_user_info(df_sessions_info, sum, ['session_duration_minutes'])\n",
    "user_downgrade = get_user_info(df_churn, avg, ['times_user_downgrade'])\n",
    "\n",
    "session_features_agg = (unique_sessions\n",
    "                        .join(unique_logs, on =['userId'], how = 'full')\n",
    "                        .join(sessions_duration, on =['userId'], how = 'full')\n",
    "                        .join(df_user_interation_info, on =['userId'], how = 'full')\n",
    "                        .join(user_downgrade, on =['userId'], how = 'full')\n",
    "                        .withColumn('session_frequency', col('countDistinct_sessionId')/col('days_between_sessions'))\n",
    "                        .withColumnRenamed('count_userId', 'count_logs')\n",
    "                        .withColumn('logs_per_sessions', col('count_logs')/col('countDistinct_sessionId'))\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(session_features_agg, number_limit = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = (df_churn\n",
    "            .withColumn('gender', when(col('gender')=='F', lit(1)).otherwise(0))\n",
    "            .withColumn('userAgent_Mac', when(col('userAgent')=='Mac', lit(1)).otherwise(0))\n",
    "            .withColumn('userAgent_Ubuntu_Linux', when(col('userAgent')=='Ubuntu/Linux', lit(1)).otherwise(0))\n",
    "            .withColumn('userAgent_Mobi', when(col('userAgent')=='Mobi', lit(1)).otherwise(0))\n",
    "            .withColumn('userAgent_Windows', when(col('userAgent')=='Windows', lit(1)).otherwise(0))\n",
    "           )\n",
    "\n",
    "\n",
    "user_features_agg = get_user_info(df_churn, max, ['gender', 'userAgent_Mac', 'userAgent_Ubuntu_Linux', \n",
    "                                                'userAgent_Mobi', 'userAgent_Windows', 'had_paid_account'\n",
    "                                               ]\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pages Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_pages = (df_churn.groupBy(\"userId\")\n",
    "               .pivot(\"page\")\n",
    "               .count()\n",
    "               .fillna(0)\n",
    "              )\n",
    "\n",
    "new_column_names = [col_name.replace(\" \", \"_\") for col_name in pivot_pages.columns]\n",
    "pivot_pages = pivot_pages.toDF(*new_column_names)\n",
    "\n",
    "pages_features_agg = pivot_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Getting all features Toghether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_agg = (song_features_agg\n",
    "                    .join(session_features_agg, on = ['userId'], how = 'full')\n",
    "                    .join(user_features_agg, on = ['userId'], how = 'full')\n",
    "                    .join(pages_features_agg, on = ['userId'], how = 'full')\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pandas_dataframe(all_features_agg, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Split the full dataset into train, test, and validation sets. Test out several of the machine learning methods you learned. Evaluate the accuracy of the various models, tuning parameters as necessary. Determine your winning model based on test accuracy and report results on the validation set. Since the churned users are a fairly small subset, I suggest using F1 score as the metric to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##defining the label \n",
    "y_label = df_churn.select('userId', 'is_user_churn').dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We will use {len(all_features_agg.columns)} features to model a churn prediction.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label.groupBy('is_user_churn').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = all_features_agg.toPandas()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize = [21, 15])\n",
    "plt.title('Features Correlation', y=1.05, size=20)\n",
    "plt.yticks(rotation = 45)\n",
    "\n",
    "ax = sns.heatmap(corr_df.iloc[:, 1:].corr().round(2), \n",
    "                annot=True, \n",
    "                square=False,\n",
    "                cbar=False, \n",
    "                linewidth=0.2,\n",
    "                cmap = 'Blues',\n",
    "                vmin = -1, \n",
    "                vmax = 1)\n",
    "\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of fetures that are strongly correlated and these features will be removed from the modeling step. Besides this, we need o redue the number of features in model.\n",
    "\n",
    "\n",
    "1. Next Songs (highly correlated to all songs features).\n",
    "2. Count Logs (highly correlated to all songs features and pages features).\n",
    "3. Sum Sessions Duration Minutes (highly correlated to all songs features and pages features).\n",
    "4. Downgrade (highly correlated to how many times a user downgrade)\n",
    "5. Sum Length and Songs Per Hour (highly correlated to distinct songs played)\n",
    "6. Cancel event, after analyse tat this feature create an overfit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_all_features_agg = all_features_agg.drop('NextSong', 'sum_sessions_duration_minutes', 'count_logs', 'Cancel', 'Downgrade',\n",
    "                                             'songs_per_hour', 'sum_length', 'count_song', 'sum_session_duration_minutes'\n",
    "                                            ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = new_all_features_agg.toPandas()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize = [21, 15])\n",
    "plt.title('Features Correlation', y=1.05, size=20)\n",
    "plt.yticks(rotation = 45)\n",
    "\n",
    "ax = sns.heatmap(corr_df.iloc[:, 1:].corr().round(2), \n",
    "                annot=True, \n",
    "                square=False,\n",
    "                cbar=False, \n",
    "                linewidth=0.2,\n",
    "                cmap = 'Blues',\n",
    "                vmin = -1, \n",
    "                vmax = 1)\n",
    "\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Applying Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##creating dataset \n",
    "data = new_all_features_agg.join(y_label, on = ['userId'], how = 'left').withColumnRenamed('is_user_churn', 'label').drop('userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier, LogisticRegression, DecisionTreeClassifier, RandomForestClassifier \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "#, Normalizer, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, seed=0):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Data will be divided into training and testing subsets. I use a fixed split ratio of 70:30.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): the model dataframe with features.\n",
    "        seed (int): a seed value of the random number generator.\n",
    "        \n",
    "    Returns:\n",
    "        train (DataFrame): the training subset.\n",
    "        test (DataFrame): the testing subset.\n",
    "    \"\"\"\n",
    "    \n",
    "    train, test = data.randomSplit([0.7, 0.3], seed=seed);\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(model, subset):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        The model's metrics computed.\n",
    "    \n",
    "    Args:\n",
    "        model: the fitted model.\n",
    "        subset: the testing/validation subset.\n",
    "        \n",
    "    Returns:\n",
    "        metrics calculated: the fitted model's metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    evaluator_multi = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction')\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction', metricName='areaUnderROC')\n",
    "\n",
    "    predict = model.transform(subset).select('label', 'prediction')\n",
    "\n",
    "    acc = evaluator_multi.evaluate(predict, {evaluator_multi.metricName: 'accuracy'})\n",
    "    f1 = evaluator_multi.evaluate(predict, {evaluator_multi.metricName: 'f1'})\n",
    "    weightedPrecision = evaluator_multi.evaluate(predict, {evaluator_multi.metricName: 'weightedPrecision'})\n",
    "    weightedRecall = evaluator_multi.evaluate(predict, {evaluator_multi.metricName: 'weightedRecall'})\n",
    "    auc = evaluator.evaluate(predict)\n",
    "    \n",
    "    metrics_calculated = pd.DataFrame(index=['F1', 'accuracy', 'weighted precision', 'weighted recall', 'AUC'],\n",
    "                                     data={'metrics value': [f1, acc, weightedPrecision, weightedRecall, auc]})\n",
    "    \n",
    "    return metrics_calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stating_process(data, seed):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Starting ML process.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): the model data.\n",
    "        seed (int): a seed value of the random number generator.\n",
    "    \n",
    "    Returns:\n",
    "        train (DataFrame): the training subset.\n",
    "        test (DataFrame): the testing subset.\n",
    "        df_features (DataFrame): df with features\n",
    "        start (Datetime): start time process\n",
    "    \"\"\"\n",
    "    print('Starting Pipeline.')\n",
    "    start = time.time()\n",
    "    df_features = data.drop('userId')\n",
    "\n",
    "    # Split data into train and test\n",
    "    train, test = split_data(df_features, seed)\n",
    "    print('Train and Test data created.')\n",
    "    \n",
    "    return train, test, df_features, start\n",
    "\n",
    "def creating_pipeline(df_features, classifier):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Creating ML Pipeline.\n",
    "    \n",
    "    Args:\n",
    "        df_features (DataFrame): the model data.\n",
    "        classifier (): a machine learning classifier.\n",
    "    \n",
    "    Returns:\n",
    "        scaler: the StandartScaler declared with features  to be used in pipeline.\n",
    "        assembler: the VectorAssembler to be used in pipeline.\n",
    "        pipeline: the pipelina with stages defined.\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = StandardScaler(inputCol='num_features', outputCol='features')\n",
    "    assembler = VectorAssembler(inputCols=(df_features.drop('label')).columns, outputCol='num_features')\n",
    "    pipeline = Pipeline(stages=[assembler, scaler, classifier])\n",
    "    print('Create pipeline done.')\n",
    "    \n",
    "    return scaler, assembler, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(data, classifier, seed=0):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Fits the machine learning model and computes metrics.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): the model data with features.\n",
    "        classifier (Lib): a machine learning classifier. \n",
    "        seed (int): a seed value of the random number generator.\n",
    "        \n",
    "    Returns:\n",
    "        model: the fitted model.\n",
    "        metrics: the model's metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    train, test, df_features, start = stating_process(data, seed)\n",
    "    print('Train and Test data created.')\n",
    "\n",
    "    scaler, assembler, pipeline = creating_pipeline(df_features, classifier)\n",
    "\n",
    "    # Training model\n",
    "    model = pipeline.fit(train)\n",
    "    print('Training done.')\n",
    "\n",
    "    # Getting metrics\n",
    "    metrics = calc_metrics(model, test)\n",
    "    print('Metrics prepared.')\n",
    "\n",
    "    duration = time.time() - start\n",
    "    \n",
    "    print(f'Model fitted. The proccess took {int(duration)} s.')\n",
    "    \n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "def plot_feature_importance(data, model):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Graph showing the importance of each feature in ML model.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): the model data with features.\n",
    "        model: the fitted model.\n",
    "        height (int): the plot's figure height.\n",
    "        title (str): the plot's title.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    features = data.drop('label')\n",
    "    print(f'Getting feature importance from model: {model.stages[-1].uid}')\n",
    "    \n",
    "    if 'LogisticRegression' in model.stages[-1].uid:\n",
    "        print('Is a Logisti model')\n",
    "        feature_coeff = model.stages[-1].coefficients\n",
    "        title = 'Model Coefficients'\n",
    "    \n",
    "    else:\n",
    "        feature_coeff = model.stages[-1].featureImportances\n",
    "        title = 'Feature Importance'\n",
    "    \n",
    "    metrics = pd.DataFrame([(str(col), coef) for col, coef in zip(features, feature_coeff)], columns=['Feature', 'FeatureImportances'])\n",
    "    metrics['Feature'] = metrics['Feature'].str.extract(r'<(.*?)>')\n",
    "    \n",
    "    indices = metrics['Feature']\n",
    "    values = metrics['FeatureImportances']\n",
    "\n",
    "    # Crie um DataFrame a partir dos índices e valores\n",
    "    feature_importances = pd.DataFrame({'Index': indices, 'Value': values})\n",
    "\n",
    "    values = feature_importances.sort_values(by='Value', ascending=False)['Value']\n",
    "    labels = feature_importances.sort_values(by='Value', ascending=False)['Index']\n",
    "\n",
    "    plt.figure(figsize = [8, 10])\n",
    "    plt.barh(np.arange(len(values)), values, height=0.6)\n",
    "    ax = plt.gca()\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    ax.set_xlabel('FeatureImportances')\n",
    "    ax.set_ylabel('Features')\n",
    "    ax.set_title(title)\n",
    "    plt.grid(True, axis='x', linewidth= 1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_cv(data, classifier, paramGrid, numFolds=2, seed=0):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        Fits the cross-validation model for tuning hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): the model data.\n",
    "        classifier (lib): a machine learning classifier. \n",
    "        paramGrid: a ParamGridBuilder object with hyperparameters.\n",
    "        numFolds: the number of folds in the cross-validation tuning.\n",
    "    \n",
    "    Returns:\n",
    "        model_cv: the cross-validation model.\n",
    "        scores_cv: the cross-validation scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    train, test, df_features, start = stating_process(data, seed)\n",
    "    \n",
    "    \n",
    "    scaler, assembler, pipeline = creating_pipeline(df_features, classifier)\n",
    "    \n",
    "    #Creating cv\n",
    "    crossValidator = CrossValidator(estimator = pipeline,\n",
    "                              estimatorParamMaps = paramGrid,\n",
    "                              evaluator = MulticlassClassificationEvaluator(),\n",
    "                              numFolds = numFolds)\n",
    "\n",
    "    #Fit cv\n",
    "    model_cv = crossValidator.fit(train)\n",
    "    \n",
    "    duration = time.time() - start  \n",
    "    print(f'Cross validation done ({int(duration)} s).')\n",
    "\n",
    "    #Calculating CV scores\n",
    "    scores = model_cv.avgMetrics\n",
    "    params_ = pd.DataFrame(\n",
    "        [{x.name: y for x, y in e.items()} for e in model_cv.getEstimatorParamMaps()]\n",
    "    )\n",
    "    params_['score'] = scores\n",
    "    \n",
    "    scores_cv = params_.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    return model_cv, scores_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark support some algorithms for Classification, based on this [documention](https://spark.apache.org/docs/latest/ml-classification-regression.html#classification).\n",
    "\n",
    "In this project, four models woulb be tested:\n",
    "\n",
    "- Gradient-boosted tree classifier\n",
    "- Logistic regression\n",
    "- Decision tree classifier\n",
    "- Random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "classifier = GBTClassifier()\n",
    "model_gbt, metrics_gradient_boost = fit_model(data, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_gradient_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(data, model_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier\n",
    "classifier = GBTClassifier()\n",
    "\n",
    "# Define params grid\n",
    "paramGrid_gbt = ParamGridBuilder() \\\n",
    "    .addGrid(classifier.maxIter, [5, 10, 20]) \\\n",
    "    .addGrid(classifier.maxDepth,[2, 3, 5]) \\\n",
    "    .addGrid(classifier.maxBins, [32, 20]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit cross-validation model\n",
    "model_gbt_cv, scores_gbt_cv = fit_model_cv(data, classifier, paramGrid_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gbt_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "classifier = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model_reg_log, metrics_reg_log = fit_model(data, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_reg_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(data, model_reg_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Logistic Regression, the absolute magnitude of the coefficients in coef can be interpreted as an indicator of feature importance. Larger absolute coefficient values suggest a stronger influence of that feature on the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "classifier = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "model_dec_tree, metrics_dec_tree = fit_model(data, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dec_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(data, model_dec_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier\n",
    "classifier = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Define params grid\n",
    "paramGrid_dec_tree = ParamGridBuilder() \\\n",
    "    .addGrid(classifier.maxDepth,[5, 10]) \\\n",
    "    .addGrid(classifier.maxBins, [32, 20]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit cross-validation model\n",
    "model_dec_tree, scores_dec_tree = fit_model_cv(data, classifier, paramGrid_dec_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dec_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "classifier = RandomForestClassifier()\n",
    "model_rand_for, metrics_rand_for = fit_model(data, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rand_for.stages[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rand_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(data, model_rand_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Define params grid\n",
    "paramGrid_rand_for = ParamGridBuilder()\\\n",
    "    .addGrid(classifier.maxBins, [10, 20, 25])\\\n",
    "    .addGrid(classifier.maxDepth, [3, 5, 10])\\\n",
    "    .addGrid(classifier.numTrees, [4, 10, 20])\\\n",
    "    .build()\n",
    "\n",
    "# Fit cross-validation model\n",
    "model_rand_for, scores_rand_for = fit_model_cv(data, classifier, paramGrid_rand_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rand_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Churn_Prediction.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
